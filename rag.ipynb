{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "def create_knowledgeBase():\n",
    "    DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "    loader = PyPDFLoader(\"./ischaemic_stroke_review_donnan_2019.pdf\")\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=150)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "    vectorstore.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_knowledgeBase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialize document retriever and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "def load_llm():\n",
    "    print(\"initializing llm....\")\n",
    "    llm = HuggingFacePipeline.from_model_id(model_id=\"gpt2\",\n",
    "                                            task=\"text-generation\", \n",
    "                                            pipeline_kwargs={\n",
    "                                                \"max_new_tokens\": 400,\n",
    "                                                \"top_p\": 0.95, \n",
    "                                                \"do_sample\": True,\n",
    "                                                \"top_k\": 50,\n",
    "                                                \"temperature\": 0.2,\n",
    "                                                \"repetition_penalty\": 2.0})\n",
    "    \n",
    "    print(\"llm initialized!\")\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def load_knowledgeBase():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "    db = FAISS.load_local(DB_FAISS_PATH, \n",
    "                          embeddings, \n",
    "                          allow_dangerous_deserialization=True)\n",
    "    return db\n",
    "\n",
    "\n",
    "def load_prompt():\n",
    "    prompt = \"\"\" You need to answer the question in the sentence as same as in the  pdf content. . \n",
    "    Given below is the context and question of the user.\n",
    "    context = {context}\n",
    "    question = {question}\n",
    "    if the answer is not in the pdf answer \"i do not know what the hell you are asking about\"\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt)\n",
    "    return prompt\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing llm....\n",
      "llm initialized!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "knowledge_base = load_knowledgeBase()\n",
    "llm = load_llm()\n",
    "prompt = load_prompt()\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "input = \"What is the ischemic stroke?\"\n",
    "similar_embeddings=knowledge_base.similarity_search(input)\n",
    "similar_embeddings=FAISS.from_documents(documents=similar_embeddings, \n",
    "                                        embedding=embeddings)\n",
    "\n",
    "retriever = similar_embeddings.as_retriever()\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  You need to answer the question in the sentence as same as in the  pdf content. . \n",
      "    Given below is the context and question of the user.\n",
      "    context = blood pressure and diabetes mellitus and is particularly \n",
      "common in Asia. Less common overall, but propor -\n",
      "tionally more prevalent in younger patients, are arte -\n",
      "rial dissection, vasculitis, patent foramen ovale (PFO) \n",
      "with paradoxical embolism (that is, whereby venous \n",
      "thrombi enter the systemic and cerebral circulation) and haematological disorders \n",
      "(fig.  2; Table  1). The cause of \n",
      "ischaemic stroke is important as it can guide therapeutic \n",
      "strategies for the prevention of recurrent stroke.\n",
      "\n",
      "Stroke is a leading cause of death and disability world-\n",
      "wide and can be broadly classified into ischaemic stroke \n",
      "and haemorrhagic stroke, the latter of which includes \n",
      "intracerebral haemorrhage and subarachnoid haem-orrhage. Ischaemic stroke is defined as infarction of the brain, spinal cord or retina\n",
      "1 and represents ~71% \n",
      "of all strokes globally2. Advances in brain imaging have \n",
      "shifted the definition of ischaemic stroke from a largely \n",
      "clinical determination to a tissue-based classification.\n",
      "\n",
      "(fig.  2; Table  1). The cause of \n",
      "ischaemic stroke is important as it can guide therapeutic \n",
      "strategies for the prevention of recurrent stroke.\n",
      "Arterial causes of stroke\n",
      "Atherosclerosis. One common cause of ischaemic \n",
      "stroke is an embolus in the cerebral vasculature (fig. 3) \n",
      "that originated from an ulcerated and typically stenotic \n",
      "atherosclerotic plaque in the aortic arch, neck or intra-\n",
      "cranial vessels. In patients with atherosclerosis, thrombi Author addresses\n",
      "\n",
      "shifted the definition of ischaemic stroke from a largely \n",
      "clinical determination to a tissue-based classification. \n",
      "Many transient events with full clinical recovery are now classed as stroke based on the identification of permanent tissue injury on MRI. Transient ischaemic \n",
      "attack (TIA) occurs when blood flow is temporarily \n",
      "interrupted and resolves before causing permanent injury. The pathogenesis is the same as ischaemic stroke, and the investigations for the underlying cause and the\n",
      "    question = What is the ischemic stroke?\n",
      "    if the answer is not in the pdf answer \"i do not know what the hell you are asking about\"\n",
      "         I am sorry that this has been so long since my last post here at http://www4lifeonline/blog/20131211_australiania_injury, i will try again soon!\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "response = rag_chain.invoke(input)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
